{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd3e06e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tomato___Bacterial_spot images: 1702\n",
      "Epoch 1/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 355ms/step - accuracy: 0.0648 - loss: 5.0068\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 0.4458 - loss: 2.0545\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 361ms/step - accuracy: 0.7850 - loss: 0.7974\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 999ms/step - accuracy: 0.9281 - loss: 0.2737\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.9740 - loss: 0.1229\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 2s/step - accuracy: 0.9821 - loss: 0.0621\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 629ms/step - accuracy: 0.9938 - loss: 0.0323\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 342ms/step - accuracy: 0.9831 - loss: 0.0778\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 358ms/step - accuracy: 0.9927 - loss: 0.0346\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 365ms/step - accuracy: 0.9970 - loss: 0.0112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16beeb0dc50>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Step 1: Set Paths\n",
    "current_path = os.getcwd()\n",
    "image_dir = os.path.join(current_path, 'New Plant Diseases Dataset(Augmented)', \n",
    "                         'New Plant Diseases Dataset(Augmented)', 'train')\n",
    "\n",
    "# Step 2: Show total images in one folder\n",
    "print(\"Total Tomato___Bacterial_spot images:\", \n",
    "      len(os.listdir(os.path.join(image_dir, 'Tomato___Bacterial_spot'))))\n",
    "\n",
    "# Step 3: Load file paths into train_dict\n",
    "train_dict = {dir: [] for dir in os.listdir(image_dir)}\n",
    "for dir in os.listdir(image_dir):\n",
    "    directory_path = os.path.join(image_dir, dir)\n",
    "    for image in os.listdir(directory_path):\n",
    "        train_dict[dir].append(os.path.join(directory_path, image))\n",
    "\n",
    "# Step 4: View sample image (optional)\n",
    "Image.open(train_dict['Tomato___Bacterial_spot'][0])\n",
    "\n",
    "# Step 5: Load images and labels efficiently\n",
    "img_arr_lst = []\n",
    "labels = []\n",
    "MAX_IMAGES_PER_CLASS = 100  # ğŸš€ Load fewer images to speed up training\n",
    "\n",
    "for key, val in train_dict.items():\n",
    "    for i, img in enumerate(val):\n",
    "        if i >= MAX_IMAGES_PER_CLASS:\n",
    "            break\n",
    "        try:\n",
    "            img_arr = cv2.imread(img)\n",
    "            if img_arr is None:\n",
    "                continue\n",
    "            resized_img = cv2.resize(img_arr, (224, 224))  # needed for model input\n",
    "            img_arr_lst.append(resized_img)\n",
    "            labels.append(key)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipped: {img} | Reason: {e}\")\n",
    "\n",
    "# Step 6: Convert to NumPy arrays\n",
    "img_arr_lst = np.array(img_arr_lst)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Step 7: Convert class names to integer labels\n",
    "label_to_index = {label: idx for idx, label in enumerate(train_dict.keys())}\n",
    "labels = np.array([label_to_index[label] for label in labels])\n",
    "num_classes = len(label_to_index)\n",
    "\n",
    "# Step 8: Train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_arr_lst, labels, test_size=0.2)\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Step 9: Define CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # ğŸ§  Multi-class output\n",
    "])\n",
    "\n",
    "# Step 10: Compile and Train Model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d034c1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.95937474e-07, 2.73135098e-10, 2.06177570e-02, ...,\n",
       "        6.57207178e-10, 6.53124236e-15, 6.33758085e-04],\n",
       "       [3.28242140e-06, 1.22501604e-01, 2.72848483e-05, ...,\n",
       "        4.04062775e-05, 3.97803269e-05, 8.26250698e-07],\n",
       "       [3.07504351e-08, 1.59688655e-03, 8.54702322e-13, ...,\n",
       "        3.03713523e-06, 2.01641953e-13, 5.57505498e-14],\n",
       "       ...,\n",
       "       [2.97584866e-05, 3.34332326e-05, 3.86883954e-07, ...,\n",
       "        3.97889926e-05, 8.08721306e-05, 4.50039588e-05],\n",
       "       [1.47486219e-06, 5.36060618e-09, 6.34777143e-06, ...,\n",
       "        2.79597769e-11, 2.32589358e-17, 1.64312883e-10],\n",
       "       [1.03468352e-04, 4.73288651e-07, 1.70180851e-04, ...,\n",
       "        1.10812206e-03, 7.83428167e-09, 7.26033642e-04]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b59e18aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=(pred>0.5).astype(int).ravel()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "026f1613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15,  1, 19, 20, 34, 29, 29, 20, 31,  8, 22, 31,  8, 22,  4, 18, 27,\n",
       "        9, 17, 14,  9, 18, 31, 14,  0,  9, 21, 10,  0,  7, 34, 10,  4, 19,\n",
       "       24, 27, 13,  3, 35, 27, 27,  1, 35, 26, 31, 30, 27, 10, 32, 35, 15,\n",
       "        3, 20, 20, 16, 27,  0, 14, 37, 12, 14,  5, 26,  6, 10, 15, 11, 33,\n",
       "       30, 25, 25,  3, 36, 11, 12,  9, 25,  3, 25, 28, 21,  8, 11, 21, 11,\n",
       "       37, 24, 32, 15, 20, 25, 17, 22, 11, 16,  1, 19,  0, 10, 29,  8, 13,\n",
       "        7, 19, 23, 12,  6,  3, 33, 34,  9, 26, 18, 13,  2, 27, 34, 37, 31,\n",
       "       25, 36, 28, 33, 13, 29, 35, 27, 30,  1,  6, 18,  7, 16, 34,  7, 22,\n",
       "        5,  5,  8,  9, 37, 14,  5,  9,  0,  4, 26,  1,  3, 27,  5, 25, 22,\n",
       "        7, 25, 26,  2, 37, 11, 27, 30, 16,  5, 35, 19, 33, 25,  2, 18, 25,\n",
       "        6, 37,  6, 35, 34,  1, 33, 33, 14, 21, 12, 37, 33, 17, 24,  5,  7,\n",
       "        0, 23, 25, 10, 35, 32,  9, 36, 18, 37, 23,  4, 36, 16, 27, 22, 32,\n",
       "       35, 15, 11, 14,  5, 15, 25, 31, 34, 20, 11, 35, 32,  4, 11, 22, 21,\n",
       "       11,  5,  8, 19, 17, 23, 17,  0,  7,  6, 27,  7, 26, 29,  8, 25, 29,\n",
       "        0, 16,  4,  4, 19,  6, 36,  7, 10, 32, 30, 36, 25, 29, 19, 32, 26,\n",
       "        8, 18,  2, 26, 10,  2, 22, 31, 19,  9, 16, 19, 25, 27,  3, 16,  9,\n",
       "        8, 30, 32, 12, 23,  3, 32, 29, 21, 36, 28, 19,  7,  4,  8, 17, 15,\n",
       "       22, 34, 27, 22, 24, 18,  7, 30, 33, 35, 21, 29, 28, 32, 24, 32,  8,\n",
       "        2, 37, 34, 16, 13,  8,  5, 36,  4, 11, 20, 23, 13, 31, 31, 20, 30,\n",
       "       10,  8, 24, 17, 26, 10, 31, 20, 36, 14, 20,  7,  3, 11, 23, 33, 31,\n",
       "       17, 26,  1, 26, 20,  7,  8,  7, 12, 27, 26, 28, 17,  0, 27, 15, 19,\n",
       "       11, 14,  5, 13, 35,  4, 24, 30, 14, 31,  0, 37, 29, 26, 25, 28,  6,\n",
       "        6, 20, 29,  5, 20, 12, 24,  3, 33, 17, 36, 25, 21, 27,  8, 14,  7,\n",
       "       20, 36, 18,  5, 36, 28, 10,  7, 33, 30,  4,  4,  4, 29,  6, 18, 15,\n",
       "       21, 34, 23, 12,  3, 18, 11, 37, 27, 23,  6, 36, 18, 19, 14, 17, 28,\n",
       "       23,  9, 27, 37, 27, 34,  7, 34, 24, 29, 25, 12, 18, 33,  8,  0,  9,\n",
       "       12, 17, 35,  3, 35, 14, 17,  7, 26, 24, 21,  9, 11,  3, 12, 35, 22,\n",
       "       13, 13, 13, 10, 26, 21,  1, 36, 22, 10, 18, 28, 35,  8, 19, 22, 27,\n",
       "       35, 28, 26, 18, 13, 25,  6, 31,  6,  4, 34, 33,  1, 15,  7, 36, 28,\n",
       "       32,  1, 33,  6, 28, 36,  0,  0,  6, 22,  1, 26, 34, 14, 21, 32, 20,\n",
       "        9, 26,  0, 22, 18, 17,  1, 10, 28,  5, 34, 20, 33, 27,  5,  5, 20,\n",
       "       27, 34, 13, 25, 10,  4, 36, 23, 29,  1, 36, 11,  9, 30,  3, 15, 33,\n",
       "       28, 20, 27,  2, 10, 33, 28,  7, 28, 19, 24, 25, 33, 21,  5,  4, 28,\n",
       "       28,  1, 10, 25, 13, 33, 34, 33, 31, 34, 30, 24, 11, 35, 28, 28, 20,\n",
       "       29,  5, 14,  4,  2, 13, 21,  2,  1, 22, 13, 24, 30,  6, 36, 31, 22,\n",
       "       21, 14, 34, 14,  5, 15, 11,  3,  4, 16, 36, 32, 29, 10, 15, 16, 17,\n",
       "       14, 19, 34, 36,  5, 18, 28, 10, 37, 20, 15, 33, 19, 26, 15, 13,  6,\n",
       "       32,  3,  4, 12, 28, 33, 31, 34, 26,  4,  5,  2, 24,  2, 17,  2, 19,\n",
       "       32, 16, 16, 12, 14,  1, 21, 12,  1, 11, 21, 36,  4, 35, 15, 35,  9,\n",
       "       32, 13,  0, 25, 35, 22, 13, 30, 26,  3,  3, 33, 33, 24, 29, 37, 30,\n",
       "       11, 36, 29,  7, 37, 15,  4, 15,  4, 18,  1,  7, 18,  8,  4, 20,  1,\n",
       "        7,  0, 31, 26, 35, 12, 36, 23, 23, 16, 33, 28, 10, 31, 34, 34, 29,\n",
       "       16, 23, 24, 25, 31,  5,  2,  2, 12, 27, 34, 23, 31, 16, 30, 29,  4,\n",
       "       32, 11, 11, 37, 19, 34, 33,  6, 27, 21,  0,  3,  1, 21, 13, 22,  9,\n",
       "       29, 21,  6, 33, 25, 37,  5,  9, 21, 32,  7,  6])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('plant_diseases_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
